{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMOuRpEqe6FmTmRmsWFGYPi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OD1992/Python-programs/blob/main/Hospi_change_point.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEVvI2FvRN5b"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats\n",
        "#import datetime\n",
        "#import time\n",
        "\n",
        "#confirmed_cases_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'\n",
        "#confirmed_cases = pd.read_csv(confirmed_cases_url, sep=',')\n",
        "#deaths_url =  'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv'\n",
        "#deaths = pd.read_csv(deaths_url, sep=',')\n",
        "#path_to_save = ''\n",
        "#confirmed_cases\n",
        "#data_end   = '5/15/20' #Take the data until yesterday\n",
        "#data_begin = '3/15/20'\n",
        "#cases_obs = np.array(confirmed_cases.loc[confirmed_cases[\"Country/Region\"] == \"Belgium\", data_begin:data_end])[0]\n",
        "#dates=confirmed_cases.loc[confirmed_cases[\"Country/Region\"] == \"Belgium\", data_begin:data_end].columns\n",
        "#np.array(dates)\n",
        "\n",
        "#*******************************************************************************************************\n",
        "#********* We decide to work with Hospi data in order to show the evolution of beta and identigy the change point\n",
        "#**************Meeting between Niko, PA and me on 12/12/2022\n",
        "#Horpitalizations data in Belgium\n",
        "import copy\n",
        "from datetime import datetime   # useful for date ranges in plots\n",
        "\n",
        "sw_dataset = 'BEL'  # !! Default: 'BEL'. Currently 'BEL' and 'FRA' are available.\n",
        "sw_districts = 'sum'  # !! Default: 'sum'. If 'sum', sums over all districts (i.e., provinces, departments...). If 'each', loop over all districts. sw_districts can also be the name of a district (for example, sw_districts = 'Brussels', or sw_districts = '75' for Paris, or sw_districts = 'London').  # PATODO fix London and stuff.\n",
        "# ***********************************************************************************\n",
        "# Load data Belgium\n",
        "# *******   \n",
        "# The data comes from https://epistat.sciensano.be/Data/COVID19BE_HOSP.csv.\n",
        "# This link was provided on 22 June 2020 by Alexey Medvedev on the \"Re R0 estimation\" channel of the O365G-covidata team on MS-Teams.\n",
        "# The link can be reached from https://epistat.wiv-isp.be/covid/\n",
        "# Some explanations can be found at https://epistat.sciensano.be/COVID19BE_codebook.pdf\n",
        "data_url='/COVID19BE_HOSP_2021-05-16.csv'\n",
        "data_raw = pd.read_csv(data_url)  # !! changed:21PA\n",
        "#fields = ['DATE', 'NR_REPORTING', 'TOTAL_IN','TOTAL_IN_ICU','TOTAL_IN_RESP','TOTAL_IN_ECMO','NEW_IN','NEW_OUT']\n",
        "\n",
        "if sw_districts == 'each':\n",
        "    data_groupbydistrict = pd.DataFrame(data_raw.groupby(\"PROVINCE\"))\n",
        "if sw_districts == 'sum':\n",
        "    nb_districts = 1\n",
        "elif sw_districts == 'each':\n",
        "    nb_districts = len(data_groupbydistrict)\n",
        "else:  # else nb_districts is the name of a district\n",
        "    nb_districts = 1\n",
        "    \n",
        "if nb_districts > 2:\n",
        "    show_figures = 0  # Force figures off if there are too many districts\n",
        "\n",
        "for cnt_district in range(nb_districts):\n",
        "\n",
        "    if sw_districts == 'sum':\n",
        "        district_name = 'sum'\n",
        "        district_names = np.array(['sum'])   # without np.array, we get an error in district_names[medians_argsort]\n",
        "    elif sw_districts == 'each':\n",
        "        district_name = data_groupbydistrict[0][cnt_district]\n",
        "        district_names = data_groupbydistrict[0]\n",
        "    else:\n",
        "        district_name = sw_districts\n",
        "        district_names = np.array([sw_districts])\n",
        "\n",
        "    # ***********************************************************************************\n",
        "    # Process data Belgium\n",
        "    # *******\n",
        "    \n",
        "    if sw_districts == 'sum':\n",
        "        data_raw_district = data_raw.groupby('DATE', as_index=False).sum()  # sum over provinces\n",
        "    elif sw_districts == 'each':\n",
        "        data_raw_district = data_groupbydistrict[1][cnt_district]  # extract province cnt_district\n",
        "    else:   \n",
        "        data_raw_district = data_raw[data_raw.iloc[:,1]==sw_districts].reset_index(drop=True)   # extract district with name sw_districts\n",
        "\n",
        "    data = data_raw_district[['DATE', 'NR_REPORTING', 'TOTAL_IN','TOTAL_IN_ICU','TOTAL_IN_RESP','TOTAL_IN_ECMO','NEW_IN','NEW_OUT']]  # exclude some useless columns\n",
        "        \n",
        "    # Extract relevant data and recompute new_out:\n",
        "    # Source: Some variable names taken from https://rpubs.com/JMBodart/Covid19-hosp-be\n",
        "    data_length = np.size(data,0)\n",
        "    data_num = data.iloc[:,1:].to_numpy(dtype=float)  # extract all rows and 2nd--last columns (recall that Python uses 0-based indexing) and turn it into a numpy array of floats. The \"float\" type is crucial due to the use of np.nan below. (Setting an integer to np.nan does not do what it is should do.)\n",
        "\n",
        "    #dates = data['DATE'])\n",
        "    dates_raw = copy.deepcopy(data['DATE'])\n",
        "    dates_raw = dates_raw.reset_index(drop=True)  # otherwise the index is not contiguous when sw_districts = 'each'\n",
        "    Dates = [None] * data_length\n",
        "    for i in range(0,data_length):\n",
        "        Dates[i] = datetime.strptime(dates_raw[i],'%Y-%m-%d')\n",
        "\n",
        "    col_total_in = 1\n",
        "    col_new_in = 5\n",
        "    col_new_out = 6\n",
        "    total_in = data_num[:,col_total_in]\n",
        "    new_in = data_num[:,col_new_in]\n",
        "    new_out_raw = data_num[:,col_new_out] # there will be a non-raw due to the \"Problem\" mentioned below.\n",
        "    new_delta = new_in - new_out_raw\n",
        "    cum_new_delta = np.cumsum(new_delta)\n",
        "    total_in_chg = np.hstack(([0],np.diff(total_in))) #difference between x[i+1]-x[i]\n",
        "    # Problem: new_delta and total_in_chg are different, though they are sometimes close. \n",
        "    # Cum_new_delta does not go back to something close to zero, whereas it should. Hence I should not trust it.\n",
        "    # I'm going to trust total_in and new_in. I deduce new_out_fixed by:\n",
        "    new_out = new_in - total_in_chg   # fixed new_out\n",
        "    data_totinout = np.c_[total_in,new_in,new_out]  # store total_in, new_in, and new_iout in an arraw with 3 columns\n",
        "\n",
        "    # Show Belgian data in figures:\n",
        "    nb_xticks = 4\n",
        "    dates_ticks = [None] * nb_xticks\n",
        "    dates_ticks_ind = np.linspace(0,len(total_in)-1,nb_xticks,dtype=int)\n",
        "    for i in range(0,nb_xticks):\n",
        "        dates_ticks[i] = Dates[dates_ticks_ind[i]]\n",
        "\n",
        "    plt.figure(figsize=(16,8))\n",
        "    plt.subplot(2,2,1)\n",
        "    plt.plot(Dates, total_in)\n",
        "    plt.plot(Dates,cum_new_delta)\n",
        "    plt.xticks(dates_ticks)\n",
        "    plt.xlabel(\"Dates\")\n",
        "    plt.ylabel(\"Values\")\n",
        "    plt.legend((\"total_in\",\"cum_new_delta\"))\n",
        "    #plt.ylim([0,1000])\n",
        "\n",
        "    plt.subplot(2,2,2)\n",
        "    plt.plot(Dates,new_delta)\n",
        "    plt.plot(Dates,total_in_chg)\n",
        "    plt.xticks(dates_ticks)\n",
        "    plt.xlabel(\"Dates\")\n",
        "    plt.ylabel(\"Values\")\n",
        "    plt.legend((\"new_delta\",\"total_in_chg\"))\n",
        "\n",
        "    plt.subplot(2,2,3)\n",
        "    plt.plot(Dates,new_out_raw)\n",
        "    plt.plot(Dates,new_out)\n",
        "    plt.xticks(dates_ticks)\n",
        "    plt.legend((\"new_out_raw\",\"new_out\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate and show the H_smooth with Moving Average method\n",
        "N = 7  # The window length of moving average will be 2N+1.\n",
        "H_smooth_MA = total_in * np.nan  # MA: moving average\n",
        "for t in np.arange(7, len(total_in)):\n",
        "    H_smooth_MA[t] = np.mean(total_in[t-N:t])\n",
        "\n",
        "nb_xticks = 4\n",
        "dates_ticks = [None] * nb_xticks\n",
        "dates_ticks_ind = np.linspace(0,len(total_in)-1,nb_xticks,dtype=int)\n",
        "for i in range(0,nb_xticks):\n",
        "    dates_ticks[i] = Dates[dates_ticks_ind[i]]\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.plot(Dates, H_smooth_MA, label=\"H_smoot\")\n",
        "plt.xticks(dates_ticks)\n",
        "plt.xlabel(\"Dates\")\n",
        "plt.ylabel(\"Values\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AFSzrXN7RTMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "H_smooth_MA = H_smooth_MA[7:]\n",
        "from scipy import optimize\n",
        "# let's define the function form\n",
        "def func(x, H_init, beta_effective):\n",
        "    #Note: beta_effective = beta-gamma\n",
        "    y = H_init* np.exp(beta_effective*x)\n",
        "    return y\n",
        "\n",
        "d=5; beta_effective = 0.23\n",
        "t_i =7; t_e = len(H_smooth_MA)-d\n",
        "beta_effective_opt = np.full(t_e, np.nan)\n",
        "H_init_opt = np.full(t_e, np.nan)\n",
        "\n",
        "for t in np.arange(t_i, t_e):\n",
        "    H_init= H_smooth_MA[t-d]\n",
        "    x = np.arange(t-d, t+d)\n",
        "    y = H_smooth_MA[t-d:t+d]\n",
        "    H_init_opt[t], beta_effective_opt[t] = optimize.curve_fit(func, xdata = x, ydata = y)[0]\n",
        "    #print(f'H_init_opt={H_init_opt[t]},  beta_effective_opt={beta_effective_opt[t]}')\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.plot(Dates[t_i:t_e], beta_effective_opt[t_i:t_e], label=\"beta_hat\")\n",
        "plt.xticks(dates_ticks)\n",
        "plt.xlabel(\"Dates\")\n",
        "plt.ylabel(\"Values\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "C6FE0GhzRa5h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}